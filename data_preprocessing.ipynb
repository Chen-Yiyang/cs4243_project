{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5560835",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests\n",
    "%pip install scikit-image\n",
    "%pip install pillow\n",
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f08ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import os\n",
    "import threading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread, imshow, imsave\n",
    "from skimage.transform import rotate\n",
    "from skimage.util import img_as_ubyte, random_noise\n",
    "from skimage.filters import gaussian\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc30a487",
   "metadata": {},
   "source": [
    "# Get Data From API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1fb611",
   "metadata": {},
   "source": [
    "## Download Image Data\n",
    "Download images for the top 10 breeds\n",
    "\n",
    "### Organisation of images downloaded:\n",
    "The data are downloaded to `./new_dog/[breed_name]/[breed_name]_xxx.jpg` where `[breed_name]` is the dog's breed and `xxx` is a 3-digit int from 000 to 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2f5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_imgs(breeds):\n",
    "    img_count = 0\n",
    "\n",
    "    # Not downloading if directory already exists\n",
    "    if not os.path.exists('old_dog'):\n",
    "        os.makedirs('old_dog')\n",
    "\n",
    "        for breed in breeds:\n",
    "\n",
    "            path_str = 'old_dog/' + breed\n",
    "            if not os.path.exists(path_str):\n",
    "                os.makedirs(path_str)\n",
    "\n",
    "            print(\"Start for breed\", breed)\n",
    "            req_str = \"https://dog.ceo/api/breed/{0}/images\".format(breed)\n",
    "            resp = requests.get(req_str).json()\n",
    "\n",
    "            img_sources = resp['message']\n",
    "            for i in range(len(img_sources)):\n",
    "\n",
    "                source = img_sources[i]\n",
    "                img_path = \"{0}/{1}_{2:03}.jpg\".format(path_str, breed, i)\n",
    "\n",
    "                #urllib.request.urlretrieve(source, img_path)\n",
    "                create_thread_for_download(source, img_path)\n",
    "\n",
    "                img_count += 1\n",
    "\n",
    "            print(\"Download all images for breed {0}.\".format(breed))\n",
    "\n",
    "        print(\"Success downloading all {0} images.\".format(img_count))\n",
    "\n",
    "\n",
    "# Use multithreading for download images\n",
    "def download_by_req(source, img_path):\n",
    "    urllib.request.urlretrieve(source, img_path)\n",
    "\n",
    "\n",
    "def create_thread_for_download(source, img_path):\n",
    "    download_thread = threading.Thread(target=download_by_req, args=(source, img_path))\n",
    "    download_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15e3841",
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_names_used = {'bulldog', 'hound', 'mountain', 'poodle', 'retriever', 'schnauzer', 'setter', 'sheepdog', 'spaniel', 'terrier'}\n",
    "breed_names_dict = {}\n",
    "# download_imgs(breed_names_used)\n",
    "label = 1\n",
    "for breed in breed_names_used:\n",
    "    breed_names_dict[breed] = label\n",
    "    label += 1\n",
    "print(breed_names_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1542c8",
   "metadata": {},
   "source": [
    "## Generate csv containing image_name, label pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe4cf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_csv(breed_names_dict):\n",
    "    csv_file = open(\"dog_data.csv\", \"w\")\n",
    "    csv_file.write(\"image_name,label\\n\")\n",
    "\n",
    "    for breed in breed_names_dict:\n",
    "        path_str = 'old_dog/' + breed\n",
    "        num_files = len([f for f in os.listdir(path_str) if os.path.isfile(os.path.join(path_str, f))])\n",
    "        for i in range(0, num_files):\n",
    "            img_path = \"{0}/{1}_{2:03}.jpg\".format(path_str, breed, i)\n",
    "            csv_file.write(\"{0},{1}\\n\".format(img_path, breed_names_dict[breed]))\n",
    "\n",
    "    csv_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fef2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_csv(breed_names_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc698ab3",
   "metadata": {},
   "source": [
    "# Resize all images\n",
    "All images will be center-cropped and resized to dimension 224 x 224 (dimensions can be changed later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b69637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize all images in all folders to be of the same dimension\n",
    "def resize_all_imgs(breed_names_dict):\n",
    "    for breed in breed_names_dict:\n",
    "        path_old_str = 'old_dog/' + breed\n",
    "        path_str = 'new_dog/' + breed\n",
    "        if not os.path.exists(path_str):\n",
    "            os.makedirs(path_str)\n",
    "\n",
    "        num_files = len([f for f in os.listdir(path_old_str) if os.path.isfile(os.path.join(path_old_str, f))])\n",
    "        for i in range(0, num_files):\n",
    "            img_path_old = \"{0}/{1}_{2:03}.jpg\".format(path_old_str, breed, i)\n",
    "            img_path = \"{0}/{1}_{2:03}.jpg\".format(path_str, breed, i)\n",
    "\n",
    "            img = Image.open(img_path_old)\n",
    "            size = min(img.size)\n",
    "            hmargin = (img.size[0] - size) // 2\n",
    "            vmargin = (img.size[1] - size) // 2\n",
    "            img = img.crop((hmargin, vmargin, size+hmargin, size+vmargin))\n",
    "            img = img.resize((128, 128))\n",
    "            img = img.convert('RGB')\n",
    "            img.save(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e79500",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_all_imgs(breed_names_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b9b95b",
   "metadata": {},
   "source": [
    "# Perform image augmentation to downloaded images\n",
    "\n",
    "Augmentations include rotations, shifting, flipping, adding noise and using cutmix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cc38c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"dog_data.csv\")\n",
    "data.head()\n",
    "all_img = []\n",
    "for image_path in tqdm(data['image_name']):\n",
    "    image_path = image_path.replace('old', 'new')\n",
    "    img = imread(image_path)\n",
    "    all_img.append(np.array(img, dtype=np.uint8))\n",
    "\n",
    "train_x = np.stack(all_img)\n",
    "train_y = data['label'].values\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc46280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decrease all elements of final_train_y by 1\n",
    "train_y -= 1\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90fd9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(train_x[np.random.choice(train_x.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fb95f4",
   "metadata": {},
   "source": [
    "## Implement Cut Mix augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b8f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lamb):\n",
    "    \"\"\" Generate random bounding box \n",
    "    Args:\n",
    "        - size: [width, breadth] of the bounding box\n",
    "        - lamb: (lambda) cut ratio parameter, sampled from Beta distribution\n",
    "    Returns:\n",
    "        - Bounding box\n",
    "    \"\"\"\n",
    "    W = size[0]\n",
    "    H = size[1]\n",
    "    cut_rat = np.sqrt(1. - lamb)\n",
    "    cut_w = np.int32(W * cut_rat)\n",
    "    cut_h = np.int32(H * cut_rat)\n",
    "\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d363bb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cutmix_image(image_batch, image_batch_labels, beta):\n",
    "    \"\"\" Generate a CutMix augmented image from a batch \n",
    "    Args:\n",
    "        - image_batch: a batch of input images\n",
    "        - image_batch_labels: labels corresponding to the image batch\n",
    "        - beta: a parameter of Beta distribution.\n",
    "    Returns:\n",
    "        - CutMix image batch, updated labels\n",
    "    \"\"\"\n",
    "    # generate mixed sample\n",
    "    lam = np.random.beta(beta, beta)\n",
    "    rand_index = np.random.permutation(len(image_batch))\n",
    "    target_a = image_batch_labels\n",
    "    target_b = image_batch_labels[rand_index]\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(image_batch[0].shape, lam)\n",
    "    image_batch_updated = image_batch.copy()\n",
    "    image_batch_updated[:, bbx1:bbx2, bby1:bby2, :] = image_batch[rand_index, bbx1:bbx2, bby1:bby2, :]\n",
    "    \n",
    "    # adjust lambda to exactly match pixel ratio\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (image_batch.shape[1] * image_batch.shape[2]))\n",
    "    label = target_a * lam + target_b * (1. - lam)\n",
    "    \n",
    "    return image_batch_updated, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b041f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read an image\n",
    "image = train_x[0]\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bfb7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Crop a random bounding box\n",
    "lamb = 0.4\n",
    "size = image.shape[0], image.shape[1]\n",
    "bbox = rand_bbox(size, lamb)\n",
    "\n",
    "# Draw bounding box on the image\n",
    "im = image.copy()\n",
    "x1 = bbox[0]\n",
    "y1 = bbox[1]\n",
    "x2 = bbox[2]\n",
    "y2 = bbox[3]\n",
    "cv2.rectangle(im, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "plt.imshow(im)\n",
    "plt.title('Original image with random bounding box')\n",
    "plt.show()\n",
    "\n",
    "# Show cropped image\n",
    "plt.imshow(image[y1:y2, x1:x2])\n",
    "plt.title('Cropped image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c8eba1",
   "metadata": {},
   "source": [
    "Check result of cutmix augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e980c834",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_mix_img, cut_mix_labels = generate_cutmix_image(train_x, train_y, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09654f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(cut_mix_img[0])\n",
    "print(cut_mix_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993474d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img = []\n",
    "final_train_x = []\n",
    "final_train_y = []\n",
    "\n",
    "for i in tqdm(range(train_x.shape[0])):\n",
    "    img, label = train_x[i], train_y[i]\n",
    "    all_img.extend([\n",
    "        img,\n",
    "        img_as_ubyte(rotate(img, angle=45, mode='wrap')),\n",
    "        np.fliplr(img),\n",
    "        np.flipud(img),\n",
    "        img_as_ubyte(random_noise(train_x[i],var=0.2**2))\n",
    "    ])\n",
    "    final_train_y.extend([train_y[i]] * 5)\n",
    "\n",
    "final_train_x = np.stack(all_img)\n",
    "final_train_y = np.array(final_train_y)\n",
    "# final_train_x = np.concatenate([final_train_x, cut_mix_img], axis=0)\n",
    "# final_train_y = np.concatenate([final_train_y, cut_mix_labels], axis=0)\n",
    "final_train_x.shape, final_train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db97dfc",
   "metadata": {},
   "source": [
    "see results of augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00746f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 5, figsize = (20, 20))\n",
    "idx = np.random.choice(train_x.shape[0])\n",
    "for i in range(5):\n",
    "    label = train_y[idx]\n",
    "    ax[i].imshow(final_train_x[idx*5 + i])\n",
    "    ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca3f7d9",
   "metadata": {},
   "source": [
    "see results of cut mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a555d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imshow(final_train_x[len(final_train_x) - 1])\n",
    "# print(final_train_y[len(final_train_y) - 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b065462f",
   "metadata": {},
   "source": [
    "#Save results as pt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b19fec2-583f-445f-87ce-c515e94ff3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tensors_data = torch.from_numpy(final_train_x).float()\n",
    "tensors_data = tensors_data.permute(0, 3, 1, 2)\n",
    "tensors_label = torch.from_numpy(final_train_y).long()\n",
    "tensors_data.size(), tensors_label.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5418f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors_data = tensors_data.contiguous()\n",
    "tensors_data.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d524a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(tensors_data, 'data/aug_data_large.pt')\n",
    "torch.save(tensors_label, 'data/aug_label_large.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
